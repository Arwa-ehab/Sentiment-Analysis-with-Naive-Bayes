{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positive_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positive_tweets[0])\n",
    "original_tweet=positive_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove #hastags\n",
    "tweet=re.sub(r'#+\\S+',\"\",original_tweet)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove @\n",
    "tweet=re.sub(r'@+\\S+',\"\",tweet)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove links\n",
    "print(positive_tweets[5])\n",
    "tweet=re.sub(r'https?://\\S+',\"\",positive_tweets[5])\n",
    "print(tweet)\n",
    "#remove any character which is not number or alphabet\n",
    "tweet=re.sub(r'[^\\w\\s]',\"\",tweet)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \\n in text\n",
    "tweet=re.sub(r'\\n',\"\",tweet)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positive_tweets[8])\n",
    "#remove emojis\n",
    "tweet=re.sub(r':\\S*',\"\",positive_tweets[8])\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(tweet):\n",
    "    tweet=re.sub(r'#+\\S+',\"\",tweet)  #remove hashtags\n",
    "    #remove @\n",
    "    tweet=re.sub(r'@+\\S+',\"\",tweet)\n",
    "    #remove links\n",
    "    tweet=re.sub(r'https?://\\S+',\"\",tweet)\n",
    "    #remove \\n in text\n",
    "    tweet=re.sub(r'\\n',\"\",tweet)\n",
    "    #remove emojis\n",
    "    tweet=re.sub(r':\\S*',\"\",tweet)\n",
    "    #remove phone numbers\n",
    "    tweet=re.sub(r'\\s\\d+\\s',\"\",tweet)\n",
    "    #remove any character which is not number or alphabet\n",
    "    tweet=re.sub(r'[^\\w\\s]',\"\",tweet)\n",
    "    #remove space at the beginning\n",
    "    tweet=re.sub(\"^\\s+\",\"\",tweet)\n",
    "    #remove space at the end\n",
    "    tweet=re.sub(\"\\s+$\",\"\",tweet)\n",
    "    return tweet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_positive_tweets=[clean_text(x) for x in positive_tweets ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_positive_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert tweets to lower text \n",
    "clean_positive_tweets=[x.lower() for x in clean_positive_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_positive_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same for negative tweets\n",
    "clean_negative_tweets=[clean_text(x) for x in negative_tweets]\n",
    "clean_negative_tweets=[x.lower() for x in clean_negative_tweets]\n",
    "clean_negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the +tweets by doing the following\n",
    "#1- remove stop words\n",
    "#2- pass the words through the stemmer \n",
    "def process_text(tweets):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "        no_stop_words= [x for x in tweet.split() if x not in stop_words]\n",
    "        clean_tweet=[stemmer.stem(x) for x in no_stop_words]\n",
    "        clean_tweets.append(clean_tweet)\n",
    "    return clean_tweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean positive tweets\n",
    "clean_positive_tweets=process_text(clean_positive_tweets)\n",
    "clean_positive_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean negative tweets\n",
    "clean_negative_tweets=process_text(clean_negative_tweets)\n",
    "clean_negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_negative_tweets=len(clean_negative_tweets)\n",
    "total_negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positive_tweets=len(clean_positive_tweets)\n",
    "total_positive_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets=[]\n",
    "all_tweets.extend(clean_positive_tweets)\n",
    "all_tweets.extend(clean_negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if positive and negative tweets got appended by chekcing the length\n",
    "len(all_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating array of positive and negative labels\n",
    "positive_labels=[1]*len(clean_positive_tweets)\n",
    "negative_labels=[0]*len(clean_negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "labels.extend(positive_labels)\n",
    "labels.extend(negative_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data\n",
    "labels\n",
    "import random\n",
    "zip_list = list((zip(all_tweets, labels)))\n",
    "random.shuffle(zip_list)\n",
    "tweets, labels = zip(*zip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freq_dict(tweets,labels):\n",
    "    freq_dict=dict()\n",
    "    #{\"word\":[count of positive,count of negative]}\n",
    "    for i,tweet in enumerate(tweets):\n",
    "        for word in tweet:\n",
    "            if word not in freq_dict.keys():\n",
    "                if labels[i]==0:\n",
    "                    freq_dict[word]=[0,1]\n",
    "                else:\n",
    "                    freq_dict[word]=[1,0]\n",
    "            else:\n",
    "                if labels[i]==0:\n",
    "                    freq_dict[word][1]+=1\n",
    "                else:\n",
    "                    freq_dict[word][0]+=1\n",
    "    return freq_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict=build_freq_dict(tweets,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_pos_neg_frequency(freq_dict):\n",
    "    pos_frequency=0\n",
    "    neg_frequency=0\n",
    "    for key,value in freq_dict.items():\n",
    "        pos_frequency+=value[0]\n",
    "        neg_frequency+=value[1]\n",
    "    return pos_frequency,neg_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_freq,neg_freq=get_total_pos_neg_frequency(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build probability\n",
    "#P(word i |pos) and P(word i|neg)\n",
    "#we will use this formula P(word i|class)=freq(word,class)+1 / Number of words in class + number of unique words\n",
    "def build_probability(freq_dict,count_pos,count_neg):\n",
    "    total_unique_words=len(freq_dict.keys())\n",
    "    probability_dict={}\n",
    "    for word, freq in freq_dict.items():\n",
    "        probability_dict[word]=[((freq[1]+1)/(count_pos+total_unique_words)),((freq[0]+1)/(count_neg+total_unique_words))]\n",
    "    return probability_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_dict=build_probability(freq_dict,pos_freq,neg_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate naive bayes inference\n",
    "#summation of log(P(w|pos)/P(w|neg) )\n",
    "#also calculate log prior = log(P(pos)/p(neg))\n",
    "def build_naive_inference(probability_dict,tweets,count_pos,count_negative):\n",
    "    predictions=[]\n",
    "    for tweet in tweets:\n",
    "        result=np.log(count_pos/count_negative)\n",
    "        for word in tweet:\n",
    "            result+=np.log(probability_dict[word][1]/probability_dict[word][0])\n",
    "        if result>=0:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=build_naive_inference(probability_dict,tweets,pos_freq,neg_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate model accuracy\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To test with new test cases we need a predict function that cleans text first and uses the inference function to get lablel\n",
    "def naive_predict(test_tweet):\n",
    "    #convert to lowercase\n",
    "    test_tweet=test_tweet.lower()\n",
    "    test_tweet=clean_text(test_tweet)\n",
    "    processed_tweet=process_text([test_tweet])\n",
    "    predictions=build_naive_inference(probability_dict,processed_tweet,pos_freq,neg_freq)\n",
    "    return predictions[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_predict(\"I am very happy today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_predict(\"My day was bad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
